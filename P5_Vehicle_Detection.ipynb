{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vehicle Detection Project\n",
    "\n",
    "The goals / steps of this project are the following:\n",
    "\n",
    "- Perform a Histogram of Oriented Gradients (HOG) feature extraction on a labeled training set of images and train a classifier Linear SVM classifier\n",
    "- Optionally, you can also apply a color transform and append binned color features, as well as histograms of color, to your HOG feature vector. \n",
    "- Note: for those first two steps don't forget to normalize your features and randomize a selection for training and testing.\n",
    "- Implement a sliding-window technique and use your trained classifier to search for vehicles in images.\n",
    "- Run your pipeline on a video stream (start with the test_video.mp4 and later implement on full project_video.mp4) and create a heat map of recurring detections frame by frame to reject outliers and follow detected vehicles.\n",
    "- Estimate a bounding box for vehicles detected.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps to take:\n",
    "\n",
    "##### Train classifier\n",
    "1. load dataset\n",
    "2. extract features from dataset - play with different feature parameters and combinations\n",
    "3. scale features using StandardScaler()\n",
    "4. split data into train and test set\n",
    "5. train classifier and test accuracy - linear SVC and other - Important is only the time to predict not the time to train since this happens only once. Maybe do RandomizedSearchCV or GridSearchCV\n",
    "\n",
    "##### Build pipeline for video processing\n",
    "6. whole image HOG (or sliding window)\n",
    "7. extract same exact features as before from every search window\n",
    "8. scale features using same scaler\n",
    "9. predict using classifier (and print found windows onto test images)\n",
    "10. add heat to heatmap\n",
    "11. integrate over several video frames and threshold\n",
    "12. use label() to get boxes to draw and draw\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import statements\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import time\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from skimage.feature import hog\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "#%matplotlib qt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8792 8968\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "images = glob.glob('./dataset/vehicles/*/*.png')\n",
    "cars = []\n",
    "for image in images:\n",
    "    cars.append(image)\n",
    "\n",
    "notcars = []\n",
    "images = glob.glob('./dataset/non-vehicles/*/*.png')\n",
    "for image in images:\n",
    "    notcars.append(image)\n",
    "\n",
    "print(len(cars), len(notcars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from skimage.feature import hog\n",
    "\n",
    "\n",
    "# Define a function to return HOG features and visualization\n",
    "def get_hog_features(img, orient, pix_per_cell, cell_per_block,\n",
    "                     vis=False, feature_vec=True):\n",
    "    # Call with two outputs if vis==True\n",
    "    if vis == True:\n",
    "        features, hog_image = hog(img, orientations=orient,\n",
    "                                  pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                                  cells_per_block=(cell_per_block, cell_per_block),\n",
    "                                  transform_sqrt=True,\n",
    "                                  visualise=vis, feature_vector=feature_vec)\n",
    "        return features, hog_image\n",
    "    # Otherwise call with one output\n",
    "    else:\n",
    "        features = hog(img, orientations=orient,\n",
    "                       pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                       cells_per_block=(cell_per_block, cell_per_block),\n",
    "                       transform_sqrt=True,\n",
    "                       visualise=vis, feature_vector=feature_vec)\n",
    "        return features\n",
    "\n",
    "\n",
    "# Define a function to compute binned color features\n",
    "def bin_spatial(img, size=(32, 32)):\n",
    "    # Use cv2.resize().ravel() to create the feature vector\n",
    "    features = cv2.resize(img, size).ravel()\n",
    "    # Return the feature vector\n",
    "    return features\n",
    "\n",
    "\n",
    "# Define a function to compute color histogram features\n",
    "# NEED TO CHANGE bins_range if reading .png files with mpimg!\n",
    "def color_hist(img, nbins=32, bins_range=(0, 256)):\n",
    "    # Compute the histogram of the color channels separately\n",
    "    channel1_hist = np.histogram(img[:, :, 0], bins=nbins, range=bins_range)\n",
    "    channel2_hist = np.histogram(img[:, :, 1], bins=nbins, range=bins_range)\n",
    "    channel3_hist = np.histogram(img[:, :, 2], bins=nbins, range=bins_range)\n",
    "    # Concatenate the histograms into a single feature vector\n",
    "    hist_features = np.concatenate((channel1_hist[0], channel2_hist[0], channel3_hist[0]))\n",
    "    # Return the individual histograms, bin_centers and feature vector\n",
    "    return hist_features\n",
    "\n",
    "\n",
    "# Define a function to extract features from a list of images\n",
    "# Have this function call bin_spatial() and color_hist()\n",
    "def extract_features(imgs, color_space='RGB', spatial_size=(32, 32),\n",
    "                     hist_bins=32, orient=9,\n",
    "                     pix_per_cell=8, cell_per_block=2, hog_channel=0,\n",
    "                     spatial_feat=True, hist_feat=True, hog_feat=True):\n",
    "    # Create a list to append feature vectors to\n",
    "    features = []\n",
    "    # Iterate through the list of images\n",
    "    for file in imgs:\n",
    "        file_features = []\n",
    "        # Read in each one by one\n",
    "        image = mpimg.imread(file)\n",
    "        # apply color conversion if other than 'RGB'\n",
    "        if color_space != 'RGB':\n",
    "            if color_space == 'HSV':\n",
    "                feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "            elif color_space == 'LUV':\n",
    "                feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2LUV)\n",
    "            elif color_space == 'HLS':\n",
    "                feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2HLS)\n",
    "            elif color_space == 'YUV':\n",
    "                feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2YUV)\n",
    "            elif color_space == 'YCrCb':\n",
    "                feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2YCrCb)\n",
    "        else:\n",
    "            feature_image = np.copy(image)\n",
    "\n",
    "        if spatial_feat == True:\n",
    "            spatial_features = bin_spatial(feature_image, size=spatial_size)\n",
    "            file_features.append(spatial_features)\n",
    "        if hist_feat == True:\n",
    "            # Apply color_hist()\n",
    "            hist_features = color_hist(feature_image, nbins=hist_bins)\n",
    "            file_features.append(hist_features)\n",
    "        if hog_feat == True:\n",
    "            # Call get_hog_features() with vis=False, feature_vec=True\n",
    "            if hog_channel == 'ALL':\n",
    "                hog_features = []\n",
    "                for channel in range(feature_image.shape[2]):\n",
    "                    hog_features.append(get_hog_features(feature_image[:, :, channel],\n",
    "                                                         orient, pix_per_cell, cell_per_block,\n",
    "                                                         vis=False, feature_vec=True))\n",
    "                hog_features = np.ravel(hog_features)\n",
    "            else:\n",
    "                hog_features = get_hog_features(feature_image[:, :, hog_channel], orient,\n",
    "                                                pix_per_cell, cell_per_block, vis=False, feature_vec=True)\n",
    "            # Append the new feature vector to the features list\n",
    "            file_features.append(hog_features)\n",
    "        features.append(np.concatenate(file_features))\n",
    "    # Return list of feature vectors\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\qi10487\\AppData\\Local\\Continuum\\Anaconda3\\envs\\carnd-term1\\lib\\site-packages\\skimage\\feature\\_hog.py:119: skimage_deprecation: Default value of `block_norm`==`L1` is deprecated and will be changed to `L2-Hys` in v0.15\n",
      "  'be changed to `L2-Hys` in v0.15', skimage_deprecation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "222.88 Seconds to extract features...\n"
     ]
    }
   ],
   "source": [
    "# extract features from dataset\n",
    "\n",
    "### TODO: Tweak these parameters and see how the results change.\n",
    "color_space = 'YCrCb'  # Can be RGB, HSV, LUV, HLS, YUV, YCrCb\n",
    "orient = 9  # HOG orientations\n",
    "pix_per_cell = 8  # HOG pixels per cell\n",
    "cell_per_block = 2  # HOG cells per block\n",
    "hog_channel = 'ALL'  # Can be 0, 1, 2, or \"ALL\"\n",
    "spatial_size = (16, 16)  # Spatial binning dimensions\n",
    "hist_bins = 16  # Number of histogram bins\n",
    "spatial_feat = True  # Spatial features on or off\n",
    "hist_feat = True  # Histogram features on or off\n",
    "hog_feat = True  # HOG features on or off\n",
    "y_start_stop = [360, 720]  # Min and max in y to search in slide_window()\n",
    "\n",
    "t = time.time()\n",
    "car_features = extract_features(cars, color_space=color_space,\n",
    "                                spatial_size=spatial_size, hist_bins=hist_bins,\n",
    "                                orient=orient, pix_per_cell=pix_per_cell,\n",
    "                                cell_per_block=cell_per_block,\n",
    "                                hog_channel=hog_channel, spatial_feat=spatial_feat,\n",
    "                                hist_feat=hist_feat, hog_feat=hog_feat)\n",
    "notcar_features = extract_features(notcars, color_space=color_space,\n",
    "                                   spatial_size=spatial_size, hist_bins=hist_bins,\n",
    "                                   orient=orient, pix_per_cell=pix_per_cell,\n",
    "                                   cell_per_block=cell_per_block,\n",
    "                                   hog_channel=hog_channel, spatial_feat=spatial_feat,\n",
    "                                   hist_feat=hist_feat, hog_feat=hog_feat)\n",
    "\n",
    "t2 = time.time()\n",
    "print(round(t2 - t, 2), 'Seconds to extract features...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using: 9 orientations 8 pixels per cell and 2 cells per block\n",
      "Feature vector length: 6108\n",
      "32.59 Seconds to train SVC...\n",
      "Test Accuracy of SVC =  0.9859\n"
     ]
    }
   ],
   "source": [
    "X = np.vstack((car_features, notcar_features)).astype(np.float64)\n",
    "# Fit a per-column scaler\n",
    "X_scaler = StandardScaler().fit(X)\n",
    "# Apply the scaler to X\n",
    "scaled_X = X_scaler.transform(X)\n",
    "\n",
    "# Define the labels vector\n",
    "y = np.hstack((np.ones(len(car_features)), np.zeros(len(notcar_features))))\n",
    "\n",
    "# Split up data into randomized training and test sets\n",
    "rand_state = np.random.randint(0, 100)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    scaled_X, y, test_size=0.2, random_state=rand_state)\n",
    "\n",
    "print('Using:', orient, 'orientations', pix_per_cell,\n",
    "      'pixels per cell and', cell_per_block, 'cells per block')\n",
    "print('Feature vector length:', len(X_train[0]))\n",
    "# Use a linear SVC\n",
    "svc = LinearSVC()\n",
    "# Check the training time for the SVC\n",
    "t = time.time()\n",
    "svc.fit(X_train, y_train)\n",
    "t2 = time.time()\n",
    "print(round(t2 - t, 2), 'Seconds to train SVC...')\n",
    "# Check the score of the SVC\n",
    "print('Test Accuracy of SVC = ', round(svc.score(X_test, y_test), 4))\n",
    "# Check the prediction time for a single sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extraction_features = {'color_space' : 'YCrCb',\n",
    "'orient' : 9, \n",
    "'pix_per_cell' : 8, \n",
    "'cell_per_block' : 2,  \n",
    "'hog_channel' : 'ALL',  \n",
    "'spatial_size' : (16, 16),  \n",
    "'hist_bins' : 16,  \n",
    "'spatial_feat' : True,  \n",
    "'hist_feat' : True,  \n",
    "'hog_feat' : True,  \n",
    "'y_start_stop' : [360, 720]}\n",
    "\n",
    "pd.Series(extraction_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(extraction_features['spatial_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>orient</th>\n",
       "      <th>pix_per_cell</th>\n",
       "      <th>cell_per_block</th>\n",
       "      <th>hog_channel</th>\n",
       "      <th>spatial_size</th>\n",
       "      <th>hist_bins</th>\n",
       "      <th>spatial_feat</th>\n",
       "      <th>hist_feat</th>\n",
       "      <th>hog_feat</th>\n",
       "      <th>y_start_stop</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time_to_train</th>\n",
       "      <th>time_to_predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>ALL</td>\n",
       "      <td>(16, 16)</td>\n",
       "      <td>16</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>[360, 720]</td>\n",
       "      <td>0.993</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>(8, 8)</td>\n",
       "      <td>16</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>[360, 720]</td>\n",
       "      <td>0.993</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>(16, 16)</td>\n",
       "      <td>16</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>[360, 720]</td>\n",
       "      <td>0.993</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>ALL</td>\n",
       "      <td>(16, 16)</td>\n",
       "      <td>16</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>[360, 720]</td>\n",
       "      <td>0.993</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   orient  pix_per_cell  cell_per_block hog_channel spatial_size  hist_bins  \\\n",
       "0       9             8               2         ALL     (16, 16)         16   \n",
       "1      12             8               2           0       (8, 8)         16   \n",
       "2       9             8               2           1     (16, 16)         16   \n",
       "3       9             8               2         ALL     (16, 16)         16   \n",
       "\n",
       "  spatial_feat hist_feat hog_feat y_start_stop  accuracy  time_to_train  \\\n",
       "0         True      True     True   [360, 720]     0.993              0   \n",
       "1         True      True     True   [360, 720]     0.993              0   \n",
       "2         True      True     True   [360, 720]     0.993              0   \n",
       "3         True      True     True   [360, 720]     0.993              0   \n",
       "\n",
       "   time_to_predict  \n",
       "0                0  \n",
       "1                0  \n",
       "2                0  \n",
       "3                0  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extraction_parameters_pd = pd.read_table(\"extraction_parameters.csv\", sep=';')\n",
    "\n",
    "print(extraction_parameters_pd.shape)\n",
    "extraction_parameters_pd['accuracy'] = 0.993\n",
    "\n",
    "extraction_parameters_pd.to_csv(\"extraction_parameters.csv\", sep=';', index=False)\n",
    "\n",
    "extraction_parameters_pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_image(image):\n",
    "    # NOTE: The output you return should be a color image (3 channel) for processing video below\n",
    "    # TODO: put your pipeline here,\n",
    "    # you should return the final output (image where lines are drawn on lanes)\n",
    "\n",
    "    return pipeline_vehicle_detection(image, debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "project_output = 'project_video_output.mp4'\n",
    "## To speed up the testing process you may want to try your pipeline on a shorter subclip of the video\n",
    "## To do so add .subclip(start_second,end_second) to the end of the line below\n",
    "## Where start_second and end_second are integer values representing the start and end of the subclip\n",
    "## You may also uncomment the following line for a subclip of the first 5 seconds\n",
    "##clip1 = VideoFileClip(\"test_videos/solidWhiteRight.mp4\").subclip(0,5)\n",
    "left = Line('left')\n",
    "right = Line('right')\n",
    "clip1 = VideoFileClip(\"project_video.mp4\")\n",
    "project_clip = clip1.fl_image(process_image) #NOTE: this function expects color images!!\n",
    "%time project_clip.write_videofile(project_output, audio=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "project_output = 'challenge_video_output.mp4'\n",
    "## To speed up the testing process you may want to try your pipeline on a shorter subclip of the video\n",
    "## To do so add .subclip(start_second,end_second) to the end of the line below\n",
    "## Where start_second and end_second are integer values representing the start and end of the subclip\n",
    "## You may also uncomment the following line for a subclip of the first 5 seconds\n",
    "##clip1 = VideoFileClip(\"test_videos/solidWhiteRight.mp4\").subclip(0,5)\n",
    "left = Line('left')\n",
    "right = Line('right')\n",
    "clip1 = VideoFileClip(\"challenge_video.mp4\")\n",
    "project_clip = clip1.fl_image(process_image) #NOTE: this function expects color images!!\n",
    "%time project_clip.write_videofile(project_output, audio=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Harder Challenge Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "project_output = 'harder_challenge_video_output.mp4'\n",
    "## To speed up the testing process you may want to try your pipeline on a shorter subclip of the video\n",
    "## To do so add .subclip(start_second,end_second) to the end of the line below\n",
    "## Where start_second and end_second are integer values representing the start and end of the subclip\n",
    "## You may also uncomment the following line for a subclip of the first 5 seconds\n",
    "##clip1 = VideoFileClip(\"test_videos/solidWhiteRight.mp4\").subclip(0,5)\n",
    "left = Line('left')\n",
    "right = Line('right')\n",
    "clip1 = VideoFileClip(\"harder_challenge_video.mp4\")\n",
    "project_clip = clip1.fl_image(process_image) #NOTE: this function expects color images!!\n",
    "%time project_clip.write_videofile(project_output, audio=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backup\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sobel_parameters(img, \n",
    "                     thresh_abs_x = (0.01, 1), \n",
    "                     thresh_abs_y = (0.01, 1), \n",
    "                     thresh_mag = (0.05, 1), \n",
    "                     thresh_dir = (0, 1)):\n",
    "    \n",
    "    # vertical contrast borders. Note that a Scharr kernel is used here for better performance \n",
    "    sobelx = cv2.Sobel(img, cv2.CV_64F, 1, 0, ksize=-1)\n",
    "    \n",
    "    # horizontal contrast borders. Scharr kernel\n",
    "    sobely = cv2.Sobel(img, cv2.CV_64F, 0, 1, ksize=-1)\n",
    "    \n",
    "    # diagonal contrast borders high->low. Scharr kernel\n",
    "    kernel10 = np.array([[0, -3, -10],[3, 0, -3],[10, 3, 0]]) \n",
    "    sobel10 = cv2.filter2D(img, -1, kernel10)\n",
    "    \n",
    "    # diagonal contrast borders low->high. Scharr kernel\n",
    "    kernel01 = np.array([[10, 3, 0],[3, 0, -3],[0, -3, -10]]) \n",
    "    sobel01 = cv2.filter2D(img, -1, kernel01)\n",
    "     \n",
    "    # calculate value (sharpness) of contrast border and apply threshold to it\n",
    "    abs_sobelx = np.absolute(sobelx)\n",
    "    abs_sobely = np.absolute(sobely)\n",
    "    \n",
    "    # threshold values \n",
    "    scaled_sobelx = abs_sobelx/np.max(abs_sobelx)\n",
    "    binary_output_x = np.zeros_like(scaled_sobelx)\n",
    "    binary_output_x[(scaled_sobelx >= thresh_abs_x[0]) & (scaled_sobelx <= thresh_abs_x[1])] = 1\n",
    "    \n",
    "    scaled_sobely = abs_sobely/np.max(abs_sobely)\n",
    "    binary_output_y = np.zeros_like(scaled_sobely)\n",
    "    binary_output_y[(scaled_sobely >= thresh_abs_y[0]) & (scaled_sobely <= thresh_abs_y[1])] = 1\n",
    "    \n",
    "    mag = np.sqrt(sobelx**2 + sobely**2)\n",
    "    scaled_mag = mag/np.max(mag)\n",
    "    binary_output_mag = np.zeros_like(scaled_mag)\n",
    "    binary_output_mag[(scaled_mag >= thresh_mag[0]) & (scaled_mag <= thresh_mag[1])] = 1\n",
    "    \n",
    "    dir_grad = np.arctan2(abs_sobely, abs_sobelx)\n",
    "    binary_output_dir = np.zeros_like(dir_grad)\n",
    "    binary_output_dir[(dir_grad > thresh_dir[0]) & (dir_grad <= thresh_dir[1])] = 1\n",
    "    \n",
    "    # put all binary images into one big numpy array\n",
    "    bin_out = img.copy()\n",
    "    bin_out = np.dstack((bin_out, binary_output_x))\n",
    "    bin_out = np.dstack((bin_out, binary_output_y))\n",
    "    bin_out = np.dstack((bin_out, binary_output_mag))\n",
    "    bin_out = np.dstack((bin_out, binary_output_dir))\n",
    "    \n",
    "    dir_mag = np.zeros_like(binary_output_dir)\n",
    "    dir_mag[(bin_out[:,:,3] == 1) & (bin_out[:,:,4] == 1)] = 1\n",
    "    bin_out = np.dstack((bin_out, dir_mag))\n",
    "    \n",
    "    combined = np.zeros_like(binary_output_dir)\n",
    "    combined[(bin_out[:,:,1] == 1) & (bin_out[:,:,2] == 1) & (bin_out[:,:,3] == 1) & (bin_out[:,:,4] == 1)] = 1\n",
    "    bin_out = np.dstack((bin_out, combined))\n",
    "    \n",
    "    \n",
    "    return bin_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "img = mpimg.imread('./test_images/test5.jpg')\n",
    "plt.figure(figsize=(17,5))\n",
    "plt.imshow(img)\n",
    "\n",
    "bin_out = sobel_parameters(img)\n",
    "plt.figure(figsize=(17,10))\n",
    "plt.imshow(bin_out[:,:,1:4], cmap='gray')\n",
    "\n",
    "\n",
    "plt.figure(figsize=(17,10))\n",
    "plt.imshow(bin_out[:,:,1], cmap='gray')\n",
    "plt.figure(figsize=(17,10))\n",
    "plt.imshow(bin_out[:,:,2], cmap='gray')\n",
    "plt.figure(figsize=(17,10))\n",
    "plt.imshow(bin_out[:,:,3], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.html.widgets import *\n",
    "\n",
    "\n",
    "def sobel(thresh_abs_x_low = 0.1, thresh_abs_x_high = 1,\n",
    "         thresh_abs_y_low = 0, thresh_abs_y_high = 1, \n",
    "         thresh_mag_low = 0, thresh_mag_high = 1,\n",
    "         thresh_dir_low = 0, thresh_dir_high=0.67):\n",
    "    \n",
    "    \n",
    "    img = mpimg.imread('./test_images/test1.jpg')\n",
    "    gray = get_redchannel(img)\n",
    "    birdview = birdview_warp(gray)\n",
    "    bin_out = sobel_parameters(birdview, \n",
    "                               thresh_abs_x = (thresh_abs_x_low, thresh_abs_x_high), \n",
    "                                thresh_abs_y = (thresh_abs_y_low, thresh_abs_y_high), \n",
    "                                thresh_mag = (thresh_mag_low, thresh_mag_high), \n",
    "                                thresh_dir = (thresh_dir_low, thresh_dir_high))\n",
    "    \n",
    "    plt.figure(figsize=(17,10))\n",
    "    #out = np.dstack((bin_out[:,:,1], bin_out[:,:,2], bin_out[:,:,5]))\n",
    "    plt.imshow(bin_out[:,:,6], cmap='gray')\n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "interact(sobel, thresh_abs_x_low = (0,1,0.01), thresh_abs_x_high = (0,1,0.01),\n",
    "         thresh_abs_y_low = (0,1,0.01), thresh_abs_y_high = (0,1,0.01), \n",
    "         thresh_mag_low = (0,1,0.01), thresh_mag_high = (0,1,0.01),\n",
    "         thresh_dir_low = (0,1.57,0.01), thresh_dir_high= (0,1.57,0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "img = mpimg.imread('./test_images/test1.jpg')\n",
    "print_example_images(img, birdview_warp(img))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## sobel demo\n",
    "img = mpimg.imread('./test_images/circle.png')\n",
    "plt.figure(figsize=(17,5))\n",
    "plt.imshow(img)\n",
    "\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=-1)\n",
    "sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=-1)\n",
    "print(sobelx.shape, sobelx.max(), sobelx.min())\n",
    "placeholder = gray.copy()\n",
    "\n",
    "# set parameters\n",
    "thresh_abs_x = (150, 255)\n",
    "thresh_abs_y = (150, 255)\n",
    "thresh_mag = (150, 255)\n",
    "thresh_dir = (0, 0.1)\n",
    "\n",
    "# abs\n",
    "abs_sobelx = np.absolute(sobelx)\n",
    "scaled_sobelx = np.uint8(255*abs_sobelx/np.max(abs_sobelx))\n",
    "binary_output_x = np.zeros_like(scaled_sobelx)\n",
    "binary_output_x[(scaled_sobelx > thresh_abs_x[0]) & (scaled_sobelx < thresh_abs_x[1])] = 1\n",
    "placeholder = np.dstack((placeholder, binary_output_x))\n",
    "\n",
    "abs_sobely = np.absolute(sobely)\n",
    "scaled_sobely = np.uint8(255*abs_sobely/np.max(abs_sobely))\n",
    "binary_output_y = np.zeros_like(scaled_sobely)\n",
    "binary_output_y[(scaled_sobely > thresh_abs_y[0]) & (scaled_sobely < thresh_abs_y[1])] = 1\n",
    "placeholder = np.dstack((placeholder, binary_output_y))\n",
    "\n",
    "# mag\n",
    "mag = np.sqrt(sobelx**2 + sobely**2)\n",
    "scaled_mag = np.uint8(255*mag/np.max(mag))\n",
    "binary_output_mag = np.zeros_like(scaled_mag)\n",
    "binary_output_mag[(scaled_mag > thresh_mag[0]) & (scaled_mag < thresh_mag[1])] = 1\n",
    "placeholder = np.dstack((placeholder, binary_output_mag))\n",
    "\n",
    "# direction\n",
    "#thresh_dir = (thresh_dir*np.pi)-(np.pi/2)\n",
    "dir_grad = np.arctan2(abs_sobely, abs_sobelx)\n",
    "binary_output_dir = np.zeros_like(dir_grad)\n",
    "binary_output_dir[(dir_grad > thresh_dir[0]) & (dir_grad <= thresh_dir[1])] = 1\n",
    "placeholder = np.dstack((placeholder, binary_output_dir))\n",
    "\n",
    "\n",
    "plt.figure(figsize=(17,5))\n",
    "plt.imshow(gray, cmap='gray')\n",
    "\n",
    "plt.figure(figsize=(17,5))\n",
    "plt.imshow(binary_output_x, cmap='gray')\n",
    "\n",
    "\n",
    "plt.figure(figsize=(17,5))\n",
    "plt.imshow(binary_output_y, cmap='gray')\n",
    "\n",
    "plt.figure(figsize=(17,5))\n",
    "plt.imshow(binary_output_mag, cmap='gray')\n",
    "\n",
    "plt.figure(figsize=(17,5))\n",
    "plt.imshow(binary_output_dir, cmap='gray')\n",
    "\n",
    "print(placeholder.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "abs_sobelx = np.absolute(sobelx)\n",
    "print(abs_sobelx.min(), abs_sobelx.max())\n",
    "scaled_sobelx = abs_sobelx/np.max(abs_sobelx)\n",
    "print(scaled_sobelx.min(), scaled_sobelx.max())\n",
    "binary_output_x = np.zeros_like(scaled_sobelx)\n",
    "binary_output_x[(scaled_sobelx >= thresh_abs_x[0]) & (scaled_sobelx <= thresh_abs_x[1])] = 1\n",
    "placeholder = np.dstack((placeholder, binary_output_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# color space demo\n",
    "from skimage import exposure\n",
    "\n",
    "img = mpimg.imread('./test_images/vlcsnap-2017-08-02-08h34m19s558.jpg')\n",
    "plt.figure(figsize=(17,5))\n",
    "plt.imshow(img)\n",
    "img = hist_equ(img)\n",
    "\n",
    "plt.figure(figsize=(17,5))\n",
    "plt.imshow(img)\n",
    "\n",
    "img_hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "#img_hsv= img\n",
    "\n",
    "plt.figure(figsize=(17,5))\n",
    "plt.imshow(img_hsv[:,:,0], cmap='gray')\n",
    "plt.figure(figsize=(17,5))\n",
    "plt.imshow(img_hsv[:,:,1], cmap='gray')\n",
    "plt.figure(figsize=(17,5))\n",
    "plt.imshow(img_hsv[:,:,2], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# lane curvature\n",
    "y_eval = 720\n",
    "\n",
    "\n",
    "\n",
    "left_curverad = ((1 + (2*left_fit_cr[0]*y_eval*ym_per_pix + left_fit_cr[1])**2)**1.5) / np.abs(2*left_fit_cr[0])\n",
    "right_curverad = ((1 + (2*right_fit_cr[0]*y_eval*ym_per_pix + right_fit_cr[1])**2)**1.5) / np.abs(2*right_fit_cr[0])\n",
    "print(left_curverad, right_curverad, 'in meters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# test with custom sobel kernel\n",
    "img = mpimg.imread('./test_images/circle.png')\n",
    "\n",
    "kernel10 = np.array([[0, -3, -10],[3, 0, -3],[10, 3, 0]]) \n",
    "\n",
    "kernel01 = np.array([[10, 3, 0],[3, 0, -3],[0, -3, -10]]) \n",
    "\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "sobel_custom1 = cv2.filter2D(gray, -1, kernel10)\n",
    "plt.figure(figsize=(17,10))\n",
    "plt.imshow(sobel_custom1, cmap='gray')\n",
    "\n",
    "sobel_custom2 = cv2.filter2D(gray, -1, kernel01)\n",
    "plt.figure(figsize=(17,10))\n",
    "plt.imshow(sobel_custom2, cmap='gray')\n",
    "\n",
    "sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=-1)\n",
    "plt.figure(figsize=(17,10))\n",
    "plt.imshow(sobelx, cmap='gray')\n",
    "\n",
    "sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=-1)\n",
    "plt.figure(figsize=(17,10))\n",
    "plt.imshow(sobely, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = np.array(range(0,3))\n",
    "\n",
    "for n in range(6,15):\n",
    "    print(x.size)\n",
    "    x = np.append(x, n)\n",
    "    if x.size > 5:\n",
    "        x = x[1:]\n",
    "    print(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = [0,1,2]\n",
    "\n",
    "for n in range(6,15):\n",
    "    print(len(x))\n",
    "    x.append(n)\n",
    "    if len(x) > 5:\n",
    "        x = x[1:]\n",
    "    print(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = np.array([[50, 48, 4, 3, 2, 1, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(np.median(a), np.mean(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = np.array([])\n",
    "a.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "left_fit.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class _alt_Lines():\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.last_detected_lines = 0\n",
    "        \n",
    "        self.left_fit_pool = np.array([])\n",
    "        self.curvature_left = 0\n",
    "           \n",
    "        self.right_fit_pool = []\n",
    "        self.curvature_left = 0\n",
    "        \n",
    "        self.offset_lane = 0\n",
    "        \n",
    "    def process_img(self, img):\n",
    "        if self.last_detected_lines == 0:\n",
    "            left_fit, right_fit, left_fit_cr, right_fit_cr = find_lines(img)\n",
    "            print(left_fit, right_fit, left_fit_cr, right_fit_cr)\n",
    "        else:\n",
    "            #TODO - simple line finding here\n",
    "            print('bla')\n",
    "        \n",
    "        if self.sanitycheck_parameters(left_fit, right_fit, left_fit_cr, right_fit_cr):     \n",
    "            self.update_parameters(left_fit, right_fit, left_fit_cr, right_fit_cr)\n",
    "        \n",
    "        \n",
    "    def sanitycheck_parameters(self, left_fit, right_fit, left_fit_cr, right_fit_cr): \n",
    "        #TODO\n",
    "        if 1 == 1:\n",
    "            self.last_detected_lines += 1\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def update_parameters(self, left_fit, right_fit, left_fit_cr, right_fit_cr):\n",
    "        \n",
    "        \n",
    "        if self.left_fit_pool.size == 0:\n",
    "            self.left_fit_pool = left_fit\n",
    "        else:\n",
    "            self.left_fit_pool = np.vstack((self.left_fit_pool, left_fit))\n",
    "            if self.left_fit_pool.shape[1] > 10:\n",
    "                self.left_fit_pool = self.left_fit_pool[1:,:]\n",
    "        print(np.median(left_fit_pool[:,0]))\n",
    "        print(np.median(left_fit_pool[:,1]))\n",
    "        print(np.median(left_fit_pool[:,2]))\n",
    "         \n",
    "        \n",
    "        # Lane curvature  ##TODO: this has to be smoothed out as well. (np.median(self.left_fit_pool))\n",
    "        y_eval = img.shape[0]\n",
    "        self.curvature_left = ((1 + (2*left_fit_cr[0]*y_eval*ym_per_pix + left_fit_cr[1])**2)**1.5) / np.abs(2*left_fit_cr[0])\n",
    "        self.curvature_right = ((1 + (2*right_fit_cr[0]*y_eval*ym_per_pix + right_fit_cr[1])**2)**1.5) / np.abs(2*right_fit_cr[0])\n",
    "        print(self.curvature_left, self.curvature_right, 'in meters')\n",
    "        \n",
    "        ## Offset\n",
    "        y= img.shape[0]\n",
    "        xl = left_fit[0]* y**2 + left_fit[1]*y + left_fit[2]  \n",
    "        xr = right_fit[0]* y**2 + right_fit[1]*y + right_fit[2]\n",
    "        print('left: ', xl)\n",
    "        print('right: ', xr)\n",
    "        center_point = img.shape[1]/2\n",
    "        self.offset_lane = (center_point - ((xr + xl)/2))*xm_per_pix\n",
    "        print('Offset from middle of the lane: ', self.offset_lane*100, 'cm')\n",
    "\n",
    "        \n",
    "## TEST         \n",
    "lines = Lines()\n",
    "img = mpimg.imread('./test_images/test5.jpg')\n",
    "red = get_redchannel(img)\n",
    "thresh = apply_threshold_dynamic2(red, percentile=0.03)\n",
    "birdview = birdview_warp(thresh)\n",
    "lines.process_img(birdview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_lines(img):\n",
    "\n",
    "    assert img.ndim == 2\n",
    "    \n",
    "    histogram = np.sum(img[360:,350:930], axis=0)\n",
    "    midpoint = np.int(histogram.shape[0]/2)\n",
    "    left_peak = np.argmax(histogram[:midpoint]) + 350\n",
    "    right_peak = np.argmax(histogram[midpoint:]) + midpoint + 350\n",
    "    print('left_peak: ', left_peak)\n",
    "    print('right_peak: ', right_peak)\n",
    "    \n",
    "    nwindows = 9\n",
    "    window_height = np.int(img.shape[0]/nwindows)\n",
    "    #left_peak = 500\n",
    "    #right_peak = 800\n",
    "    margin = 100\n",
    "    adjust_window_pos = 50\n",
    "    left_lane_coordx = np.array([])\n",
    "    left_lane_coordy = np.array([])\n",
    "    right_lane_coordx = np.array([])\n",
    "    right_lane_coordy = np.array([])\n",
    "\n",
    "    for n in range(nwindows):\n",
    "        window_lower_border = img.shape[0] - n*window_height\n",
    "        window_slice = img[window_lower_border-window_height:window_lower_border, :]\n",
    "\n",
    "        slice_left_window = window_slice[: , left_peak-margin:left_peak+margin]\n",
    "        slice_left_line_coordy, slice_left_line_coordx = np.nonzero(slice_left_window)\n",
    "        slice_left_line_coordy += window_lower_border - window_height\n",
    "        slice_left_line_coordx += left_peak - 100\n",
    "\n",
    "        left_lane_coordx = np.append(left_lane_coordx, slice_left_line_coordx)\n",
    "        left_lane_coordy = np.append(left_lane_coordy, slice_left_line_coordy)\n",
    "\n",
    "        if slice_left_line_coordx.size > adjust_window_pos:\n",
    "            left_peak = np.int(np.mean(slice_left_line_coordx))\n",
    "\n",
    "\n",
    "        slice_right_window = window_slice[: , right_peak-margin:right_peak+margin]\n",
    "        slice_right_line_coordy, slice_right_line_coordx = np.nonzero(slice_right_window)\n",
    "        slice_right_line_coordy += window_lower_border - window_height\n",
    "        slice_right_line_coordx += right_peak - 100\n",
    "\n",
    "        right_lane_coordx = np.append(right_lane_coordx, slice_right_line_coordx)\n",
    "        right_lane_coordy = np.append(right_lane_coordy, slice_right_line_coordy)\n",
    "\n",
    "        if slice_right_line_coordx.size > adjust_window_pos:\n",
    "            right_peak = np.int(np.mean(slice_right_line_coordx))\n",
    "\n",
    "\n",
    "    assert left_lane_coordx.size == left_lane_coordy.size\n",
    "    assert right_lane_coordx.size == right_lane_coordy.size\n",
    "\n",
    "    left_fit_cr = np.polyfit(left_lane_coordy*ym_per_pix, left_lane_coordx*xm_per_pix, 2)\n",
    "    right_fit_cr = np.polyfit(right_lane_coordy*ym_per_pix, right_lane_coordx*xm_per_pix, 2)    \n",
    "    \n",
    "    left_fit = np.polyfit(left_lane_coordy, left_lane_coordx, 2)\n",
    "    right_fit = np.polyfit(right_lane_coordy, right_lane_coordx, 2)    \n",
    "    \n",
    "\n",
    "    return left_fit, right_fit, left_fit_cr, right_fit_cr\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "img = mpimg.imread('./test_images/test5.jpg')\n",
    "red = get_redchannel(img)\n",
    "thresh = apply_threshold_dynamic2(red, percentile=0.03)\n",
    "birdview = birdview_warp(thresh)\n",
    "left_fit, right_fit, left_fit_cr, right_fit_cr = find_lines(birdview)\n",
    "print(left_fit, right_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def findlines(img):\n",
    "    \n",
    "    histogram = np.sum(img[int(img.shape[0]/2):,400:880], axis=0)\n",
    "    # Create an output image to draw on and  visualize the result\n",
    "    out_img = np.dstack((img, img, img))*255\n",
    "    # Find the peak of the left and right halves of the histogram\n",
    "    # These will be the starting point for the left and right lines\n",
    "    midpoint = np.int(histogram.shape[0]/2)\n",
    "    leftx_base = np.argmax(histogram[:midpoint])\n",
    "    rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "\n",
    "    # Choose the number of sliding windows\n",
    "    nwindows = 9\n",
    "    # Set height of windows\n",
    "    window_height = np.int(img.shape[0]/nwindows)\n",
    "    # Identify the x and y positions of all nonzero pixels in the image\n",
    "    nonzero = img.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    # Current positions to be updated for each window\n",
    "    leftx_current = leftx_base + 400\n",
    "    rightx_current = rightx_base + 400\n",
    "    # Set the width of the windows +/- margin\n",
    "    margin = 100\n",
    "    # Set minimum number of pixels found to recenter window\n",
    "    minpix = 50\n",
    "    # Create empty lists to receive left and right lane pixel indices\n",
    "    left_lane_inds = []\n",
    "    right_lane_inds = []\n",
    "\n",
    "    # Step through the windows one by one\n",
    "    for window in range(nwindows):\n",
    "        # Identify window boundaries in x and y (and right and left)\n",
    "        win_y_low = img.shape[0] - (window+1)*window_height\n",
    "        win_y_high = img.shape[0] - window*window_height\n",
    "        win_xleft_low = leftx_current - margin\n",
    "        win_xleft_high = leftx_current + margin\n",
    "        win_xright_low = rightx_current - margin\n",
    "        win_xright_high = rightx_current + margin\n",
    "        # Draw the windows on the visualization image\n",
    "        cv2.rectangle(out_img,(win_xleft_low,win_y_low),(win_xleft_high,win_y_high),(0,255,0), 2) \n",
    "        cv2.rectangle(out_img,(win_xright_low,win_y_low),(win_xright_high,win_y_high),(0,255,0), 2) \n",
    "        # Identify the nonzero pixels in x and y within the window\n",
    "        good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & (nonzerox >= win_xleft_low) & (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "        good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & (nonzerox >= win_xright_low) & (nonzerox < win_xright_high)).nonzero()[0]\n",
    "        # Append these indices to the lists\n",
    "        left_lane_inds.append(good_left_inds)\n",
    "        right_lane_inds.append(good_right_inds)\n",
    "        # If you found > minpix pixels, recenter next window on their mean position\n",
    "        if len(good_left_inds) > minpix:\n",
    "            leftx_current = np.int(np.mean(nonzerox[good_left_inds]))\n",
    "        if len(good_right_inds) > minpix:        \n",
    "            rightx_current = np.int(np.mean(nonzerox[good_right_inds]))\n",
    "\n",
    "    # Concatenate the arrays of indices\n",
    "    left_lane_inds = np.concatenate(left_lane_inds)\n",
    "    right_lane_inds = np.concatenate(right_lane_inds)\n",
    "\n",
    "    # Extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds] \n",
    "\n",
    "    \n",
    "    \n",
    "    # Fit a second order polynomial to each\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "    \n",
    "    # Generate x and y values for plotting\n",
    "    ploty = np.linspace(0, img.shape[0]-1, img.shape[0] )\n",
    "    left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "    right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "\n",
    "    out_img[nonzeroy[left_lane_inds], nonzerox[left_lane_inds]] = [255, 0, 0]\n",
    "    out_img[nonzeroy[right_lane_inds], nonzerox[right_lane_inds]] = [0, 0, 255]\n",
    "    \n",
    "    print(nonzeroy[left_lane_inds])\n",
    "    \n",
    "    \n",
    "    plt.figure(figsize=(17,5))\n",
    "    plt.imshow(out_img)\n",
    "    plt.plot(left_fitx, ploty, color='yellow')\n",
    "    plt.plot(right_fitx, ploty, color='yellow')\n",
    "    plt.xlim(0, 1280)\n",
    "    plt.ylim(720, 0)\n",
    "    plt.show()\n",
    "    \n",
    "    return left_fit, right_fit, leftx, lefty, rightx, righty\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "## Demo\n",
    "img = mpimg.imread('./test_images/test4.jpg')\n",
    "red = get_redchannel(img)\n",
    "thresh = apply_threshold_dynamic2(red, percentile=0.03)\n",
    "birdview = birdview_warp(thresh)\n",
    "left_fit, right_fit, leftx, lefty, rightx, righty = findlines(birdview)\n",
    "print_example_images(img, thresh)\n",
    "\n",
    "print(leftx)\n",
    "print(lefty)\n",
    "\n",
    "# Generate x and y values for plotting\n",
    "ploty = np.linspace(0, img.shape[0]-1, img.shape[0] )\n",
    "left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "\n",
    "\n",
    "plt.figure(figsize=(17,5))\n",
    "plt.imshow(birdview_warp(img), cmap='gray')\n",
    "plt.plot(left_fitx, ploty, color='yellow')\n",
    "plt.plot(right_fitx, ploty, color='yellow')\n",
    "plt.xlim(0, 1280)\n",
    "plt.ylim(720, 0)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "left_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = np.vstack((left_fit, left_fit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = np.vstack((test, right_fit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test[1:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = np.array([1,1,1])\n",
    "for n in range(10):\n",
    "    test = np.vstack((test, np.array([n,n,n])))\n",
    "    \n",
    "    if test.shape[0] > 3:\n",
    "        test = test[1:,:]\n",
    "    print(test)\n",
    "    #print(test.mean())\n",
    "    print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
