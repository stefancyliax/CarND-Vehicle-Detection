{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vehicle Detection Project\n",
    "\n",
    "The goals / steps of this project are the following:\n",
    "\n",
    "- Perform a Histogram of Oriented Gradients (HOG) feature extraction on a labeled training set of images and train a classifier Linear SVM classifier\n",
    "- Optionally, you can also apply a color transform and append binned color features, as well as histograms of color, to your HOG feature vector. \n",
    "- Note: for those first two steps don't forget to normalize your features and randomize a selection for training and testing.\n",
    "- Implement a sliding-window technique and use your trained classifier to search for vehicles in images.\n",
    "- Run your pipeline on a video stream (start with the test_video.mp4 and later implement on full project_video.mp4) and create a heat map of recurring detections frame by frame to reject outliers and follow detected vehicles.\n",
    "- Estimate a bounding box for vehicles detected.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps to take:\n",
    "\n",
    "##### Train classifier\n",
    "1. load dataset\n",
    "2. extract features from dataset - play with different feature parameters and combinations\n",
    "3. scale features using StandardScaler()\n",
    "4. split data into train and test set\n",
    "5. train classifier and test accuracy - linear SVC and other - Important is only the time to predict not the time to train since this happens only once. Maybe do RandomizedSearchCV or GridSearchCV\n",
    "\n",
    "##### Build pipeline for video processing\n",
    "6. whole image HOG (or sliding window)\n",
    "7. extract same exact features as before from every search window\n",
    "8. scale features using same scaler\n",
    "9. predict using classifier (and print found windows onto test images)\n",
    "10. add heat to heatmap\n",
    "11. integrate over several video frames and threshold\n",
    "12. use label() to get boxes to draw and draw\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import statements\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import time\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from skimage.feature import hog\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "#%matplotlib qt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8792 8968\n",
      "500 500\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "images = glob.glob('./dataset/vehicles/*/*.png')\n",
    "cars = []\n",
    "for image in images:\n",
    "    cars.append(image)\n",
    "\n",
    "notcars = []\n",
    "images = glob.glob('./dataset/non-vehicles/*/*.png')\n",
    "for image in images:\n",
    "    notcars.append(image)\n",
    "\n",
    "print(len(cars), len(notcars))\n",
    "\n",
    "subset = 500\n",
    "\n",
    "if subset != None:\n",
    "    cars = cars[0:subset]\n",
    "    notcars = notcars[0:subset]\n",
    "\n",
    "    print(len(cars), len(notcars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from skimage.feature import hog\n",
    "\n",
    "\n",
    "# Define a function to return HOG features and visualization\n",
    "def get_hog_features(img, orient, pix_per_cell, cell_per_block,\n",
    "                     vis=False, feature_vec=True):\n",
    "    # Call with two outputs if vis==True\n",
    "    if vis == True:\n",
    "        features, hog_image = hog(img, orientations=orient,\n",
    "                                  pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                                  cells_per_block=(cell_per_block, cell_per_block),\n",
    "                                  transform_sqrt=True,\n",
    "                                  visualise=vis, feature_vector=feature_vec, block_norm='L2-Hys')\n",
    "        return features, hog_image\n",
    "    # Otherwise call with one output\n",
    "    else:\n",
    "        features = hog(img, orientations=orient,\n",
    "                       pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                       cells_per_block=(cell_per_block, cell_per_block),\n",
    "                       transform_sqrt=True,\n",
    "                       visualise=vis, feature_vector=feature_vec, block_norm='L2-Hys')\n",
    "        return features\n",
    "\n",
    "\n",
    "# Define a function to compute binned color features\n",
    "def bin_spatial(img, size=(32, 32)):\n",
    "    # Use cv2.resize().ravel() to create the feature vector\n",
    "    features = cv2.resize(img, size).ravel()\n",
    "    # Return the feature vector\n",
    "    return features\n",
    "\n",
    "\n",
    "# Define a function to compute color histogram features\n",
    "# NEED TO CHANGE bins_range if reading .png files with mpimg!\n",
    "def color_hist(img, nbins=32, bins_range=(0, 256)):\n",
    "    # Compute the histogram of the color channels separately\n",
    "    channel1_hist = np.histogram(img[:, :, 0], bins=nbins, range=bins_range)\n",
    "    channel2_hist = np.histogram(img[:, :, 1], bins=nbins, range=bins_range)\n",
    "    channel3_hist = np.histogram(img[:, :, 2], bins=nbins, range=bins_range)\n",
    "    # Concatenate the histograms into a single feature vector\n",
    "    hist_features = np.concatenate((channel1_hist[0], channel2_hist[0], channel3_hist[0]))\n",
    "    # Return the individual histograms, bin_centers and feature vector\n",
    "    return hist_features\n",
    "\n",
    "\n",
    "# Define a function to extract features from a list of images\n",
    "# Have this function call bin_spatial() and color_hist()\n",
    "def extract_features(imgs, color_space='RGB', spatial_size=(32, 32),\n",
    "                     hist_bins=32, orient=9,\n",
    "                     pix_per_cell=8, cell_per_block=2, hog_channel=0,\n",
    "                     spatial_feat=True, hist_feat=True, hog_feat=True):\n",
    "    # Create a list to append feature vectors to\n",
    "    features = []\n",
    "    # Iterate through the list of images\n",
    "    for file in tqdm(imgs):\n",
    "        # TODO: refactor all below to new function for later usage\n",
    "        file_features = []\n",
    "        # Read in each one by one\n",
    "        image = mpimg.imread(file)\n",
    "        # apply color conversion if other than 'RGB'\n",
    "        if color_space != 'RGB':\n",
    "            if color_space == 'HSV':\n",
    "                feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "            elif color_space == 'LUV':\n",
    "                feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2LUV)\n",
    "            elif color_space == 'HLS':\n",
    "                feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2HLS)\n",
    "            elif color_space == 'YUV':\n",
    "                feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2YUV)\n",
    "            elif color_space == 'YCrCb':\n",
    "                feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2YCrCb)\n",
    "        else:\n",
    "            feature_image = np.copy(image)\n",
    "\n",
    "        if spatial_feat == True:\n",
    "            spatial_features = bin_spatial(feature_image, size=spatial_size)\n",
    "            file_features.append(spatial_features)\n",
    "        if hist_feat == True:\n",
    "            # Apply color_hist()\n",
    "            hist_features = color_hist(feature_image, nbins=hist_bins)\n",
    "            file_features.append(hist_features)\n",
    "        if hog_feat == True:\n",
    "            # Call get_hog_features() with vis=False, feature_vec=True\n",
    "            if hog_channel == -1:\n",
    "                hog_features = []\n",
    "                for channel in range(feature_image.shape[2]):\n",
    "                    hog_features.append(get_hog_features(feature_image[:, :, channel],\n",
    "                                                         orient, pix_per_cell, cell_per_block,\n",
    "                                                         vis=False, feature_vec=True))\n",
    "                hog_features = np.ravel(hog_features)\n",
    "            else:\n",
    "                hog_features = get_hog_features(feature_image[:, :, hog_channel], orient,\n",
    "                                                pix_per_cell, cell_per_block, vis=False, feature_vec=True)\n",
    "            # Append the new feature vector to the features list\n",
    "            file_features.append(hog_features)\n",
    "        features.append(np.concatenate(file_features))\n",
    "    # Return list of feature vectors\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                  | 0/500 [00:00<?, ?it/s]\n",
      "  2%|▉                                       | 11/500 [00:00<00:04, 105.98it/s]\n",
      "  4%|█▊                                      | 22/500 [00:00<00:04, 106.49it/s]\n",
      "  7%|██▋                                     | 33/500 [00:00<00:04, 106.69it/s]\n",
      "  9%|███▌                                    | 44/500 [00:00<00:04, 105.59it/s]\n",
      " 11%|████▍                                   | 55/500 [00:00<00:04, 106.52it/s]\n",
      " 13%|█████▎                                  | 66/500 [00:00<00:04, 107.18it/s]\n",
      " 15%|██████▏                                 | 77/500 [00:00<00:03, 107.33it/s]\n",
      " 18%|███████                                 | 89/500 [00:00<00:03, 108.39it/s]\n",
      " 20%|███████▊                               | 100/500 [00:00<00:03, 108.18it/s]\n",
      " 22%|████████▋                              | 111/500 [00:01<00:03, 108.03it/s]\n",
      " 24%|█████████▌                             | 122/500 [00:01<00:03, 107.92it/s]\n",
      " 27%|██████████▎                            | 133/500 [00:01<00:03, 107.85it/s]\n",
      " 29%|███████████▏                           | 144/500 [00:01<00:03, 107.80it/s]\n",
      " 31%|████████████                           | 155/500 [00:01<00:03, 107.45it/s]\n",
      " 33%|████████████▉                          | 166/500 [00:01<00:03, 107.52it/s]\n",
      " 35%|█████████████▊                         | 177/500 [00:01<00:03, 107.25it/s]\n",
      " 38%|██████████████▋                        | 188/500 [00:01<00:02, 107.38it/s]\n",
      " 40%|███████████████▌                       | 199/500 [00:01<00:02, 107.16it/s]\n",
      " 42%|████████████████▍                      | 210/500 [00:01<00:02, 107.67it/s]\n",
      " 44%|█████████████████▏                     | 221/500 [00:02<00:02, 107.36it/s]\n",
      " 46%|██████████████████                     | 232/500 [00:02<00:02, 106.52it/s]\n",
      " 49%|██████████████████▉                    | 243/500 [00:02<00:02, 106.55it/s]\n",
      " 51%|███████████████████▊                   | 254/500 [00:02<00:02, 105.96it/s]\n",
      " 53%|████████████████████▋                  | 265/500 [00:02<00:02, 106.26it/s]\n",
      " 55%|█████████████████████▌                 | 276/500 [00:02<00:02, 106.51it/s]\n",
      " 57%|██████████████████████▍                | 287/500 [00:02<00:01, 106.70it/s]\n",
      " 60%|███████████████████████▏               | 298/500 [00:02<00:01, 107.00it/s]\n",
      " 62%|████████████████████████               | 309/500 [00:02<00:01, 106.89it/s]\n",
      " 64%|████████████████████████▉              | 320/500 [00:02<00:01, 106.50it/s]\n",
      " 66%|█████████████████████████▊             | 331/500 [00:03<00:01, 105.02it/s]\n",
      " 68%|██████████████████████████▋            | 342/500 [00:03<00:01, 105.80it/s]\n",
      " 71%|███████████████████████████▌           | 353/500 [00:03<00:01, 105.74it/s]\n",
      " 73%|████████████████████████████▍          | 364/500 [00:03<00:01, 106.01it/s]\n",
      " 75%|█████████████████████████████▎         | 375/500 [00:03<00:01, 106.04it/s]\n",
      " 77%|██████████████████████████████         | 386/500 [00:03<00:01, 105.30it/s]\n",
      " 79%|██████████████████████████████▉        | 397/500 [00:03<00:00, 105.89it/s]\n",
      " 82%|███████████████████████████████▊       | 408/500 [00:03<00:00, 106.52it/s]\n",
      " 84%|████████████████████████████████▋      | 419/500 [00:03<00:00, 105.67it/s]\n",
      " 86%|█████████████████████████████████▌     | 430/500 [00:04<00:00, 105.35it/s]\n",
      " 88%|██████████████████████████████████▍    | 441/500 [00:04<00:00, 105.43it/s]\n",
      " 90%|███████████████████████████████████▎   | 452/500 [00:04<00:00, 105.18it/s]\n",
      " 93%|████████████████████████████████████   | 463/500 [00:04<00:00, 102.36it/s]\n",
      " 95%|████████████████████████████████████▉  | 474/500 [00:04<00:00, 102.74it/s]\n",
      " 97%|█████████████████████████████████████▊ | 485/500 [00:04<00:00, 100.18it/s]\n",
      " 99%|██████████████████████████████████████▋| 496/500 [00:04<00:00, 102.32it/s]\n",
      "100%|███████████████████████████████████████| 500/500 [00:04<00:00, 105.97it/s]\n",
      "  0%|                                                  | 0/500 [00:00<?, ?it/s]\n",
      "  2%|▉                                       | 11/500 [00:00<00:04, 100.58it/s]\n",
      "  4%|█▋                                      | 21/500 [00:00<00:04, 100.06it/s]\n",
      "  6%|██▌                                     | 32/500 [00:00<00:04, 101.95it/s]\n",
      "  9%|███▍                                    | 43/500 [00:00<00:04, 103.37it/s]\n",
      " 11%|████▎                                   | 54/500 [00:00<00:04, 104.63it/s]\n",
      " 13%|█████▏                                  | 65/500 [00:00<00:04, 105.83it/s]\n",
      " 15%|██████                                  | 76/500 [00:00<00:03, 106.07it/s]\n",
      " 17%|██████▉                                 | 87/500 [00:00<00:03, 107.17it/s]\n",
      " 20%|███████▊                                | 98/500 [00:00<00:03, 107.33it/s]\n",
      " 22%|████████▌                              | 109/500 [00:01<00:03, 107.75it/s]\n",
      "100%|███████████████████████████████████████| 500/500 [00:04<00:00, 108.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.35 Seconds to extract features...\n"
     ]
    }
   ],
   "source": [
    "# extract features from dataset\n",
    "\n",
    "### TODO: Tweak these parameters and see how the results change.\n",
    "color_space = 'YCrCb'  # Can be RGB, HSV, LUV, HLS, YUV, YCrCb\n",
    "orient = 9  # HOG orientations\n",
    "pix_per_cell = 8  # HOG pixels per cell\n",
    "cell_per_block = 2  # HOG cells per block\n",
    "hog_channel = -1  # Can be 0, 1, 2, or \"ALL\"\n",
    "spatial_size = (16, 16)  # Spatial binning dimensions\n",
    "hist_bins = 16  # Number of histogram bins\n",
    "spatial_feat = True  # Spatial features on or off\n",
    "hist_feat = True  # Histogram features on or off\n",
    "hog_feat = True  # HOG features on or off\n",
    "\n",
    "t = time.time()\n",
    "car_features = extract_features(cars, color_space=color_space,\n",
    "                                spatial_size=spatial_size, hist_bins=hist_bins,\n",
    "                                orient=orient, pix_per_cell=pix_per_cell,\n",
    "                                cell_per_block=cell_per_block,\n",
    "                                hog_channel=hog_channel, spatial_feat=spatial_feat,\n",
    "                                hist_feat=hist_feat, hog_feat=hog_feat)\n",
    "notcar_features = extract_features(notcars, color_space=color_space,\n",
    "                                   spatial_size=spatial_size, hist_bins=hist_bins,\n",
    "                                   orient=orient, pix_per_cell=pix_per_cell,\n",
    "                                   cell_per_block=cell_per_block,\n",
    "                                   hog_channel=hog_channel, spatial_feat=spatial_feat,\n",
    "                                   hist_feat=hist_feat, hog_feat=hog_feat)\n",
    "\n",
    "t2 = time.time()\n",
    "print(round(t2 - t, 2), 'Seconds to extract features...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using: 9 orientations 8 pixels per cell and 2 cells per block\n",
      "Feature vector length: 6108\n",
      "0.54 Seconds to train SVC...\n",
      "Test Accuracy of SVC =  1.0\n"
     ]
    }
   ],
   "source": [
    "X = np.vstack((car_features, notcar_features)).astype(np.float64)\n",
    "# Fit a per-column scaler\n",
    "X_scaler = StandardScaler().fit(X)\n",
    "# Apply the scaler to X\n",
    "scaled_X = X_scaler.transform(X)\n",
    "\n",
    "# Define the labels vector\n",
    "y = np.hstack((np.ones(len(car_features)), np.zeros(len(notcar_features))))\n",
    "\n",
    "# Split up data into randomized training and test sets\n",
    "rand_state = np.random.randint(0, 100)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    scaled_X, y, test_size=0.2, random_state=rand_state)\n",
    "\n",
    "print('Using:', orient, 'orientations', pix_per_cell,\n",
    "      'pixels per cell and', cell_per_block, 'cells per block')\n",
    "print('Feature vector length:', len(X_train[0]))\n",
    "# Use a linear SVC\n",
    "kernel = 'linear'\n",
    "svc = SVC(kernel = kernel)\n",
    "# Check the training time for the SVC\n",
    "t = time.time()\n",
    "svc.fit(X_train, y_train)\n",
    "t2 = time.time()\n",
    "print(round(t2 - t, 2), 'Seconds to train SVC...')\n",
    "# Check the score of the SVC\n",
    "print('Test Accuracy of SVC = ', round(svc.score(X_test, y_test), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11, 11)\n",
      "Index:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 500/500 [00:04<00:00, 110.12it/s]\n",
      "100%|███████████████████████████████████████| 500/500 [00:04<00:00, 109.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 500/500 [00:01<00:00, 272.32it/s]\n",
      "100%|███████████████████████████████████████| 500/500 [00:01<00:00, 269.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index:  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 500/500 [00:04<00:00, 110.75it/s]\n",
      "100%|███████████████████████████████████████| 500/500 [00:04<00:00, 109.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index:  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 500/500 [00:04<00:00, 109.98it/s]\n",
      "100%|███████████████████████████████████████| 500/500 [00:04<00:00, 110.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index:  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 500/500 [00:04<00:00, 110.18it/s]\n",
      "100%|███████████████████████████████████████| 500/500 [00:04<00:00, 110.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index:  5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 500/500 [00:04<00:00, 110.75it/s]\n",
      "100%|███████████████████████████████████████| 500/500 [00:04<00:00, 109.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index:  6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 500/500 [00:04<00:00, 107.91it/s]\n",
      "100%|███████████████████████████████████████| 500/500 [00:04<00:00, 108.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index:  7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 500/500 [00:04<00:00, 109.25it/s]\n",
      "100%|███████████████████████████████████████| 500/500 [00:04<00:00, 109.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index:  8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 500/500 [00:04<00:00, 110.01it/s]\n",
      "100%|███████████████████████████████████████| 500/500 [00:04<00:00, 110.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index:  9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 500/500 [00:04<00:00, 110.15it/s]\n",
      "100%|███████████████████████████████████████| 500/500 [00:04<00:00, 110.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index:  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 500/500 [00:00<00:00, 2889.72it/s]\n",
      "100%|██████████████████████████████████████| 500/500 [00:00<00:00, 2987.68it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kernel</th>\n",
       "      <th>color_space</th>\n",
       "      <th>orient</th>\n",
       "      <th>pix_per_cell</th>\n",
       "      <th>cell_per_block</th>\n",
       "      <th>hog_channel</th>\n",
       "      <th>spatial_size</th>\n",
       "      <th>hist_bins</th>\n",
       "      <th>spatial_feat</th>\n",
       "      <th>hist_feat</th>\n",
       "      <th>hog_feat</th>\n",
       "      <th>time_to_extract_features</th>\n",
       "      <th>features_vector_length</th>\n",
       "      <th>training_time</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>prediction_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>linear</td>\n",
       "      <td>YCrCb</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>9.10</td>\n",
       "      <td>6108.0</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.995</td>\n",
       "      <td>0.000551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>linear</td>\n",
       "      <td>YCrCb</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>3.71</td>\n",
       "      <td>2592.0</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.990</td>\n",
       "      <td>0.000200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rbf</td>\n",
       "      <td>YCrCb</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>9.07</td>\n",
       "      <td>6108.0</td>\n",
       "      <td>1.09</td>\n",
       "      <td>0.995</td>\n",
       "      <td>0.001353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>poly</td>\n",
       "      <td>YCrCb</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>9.09</td>\n",
       "      <td>6108.0</td>\n",
       "      <td>2.25</td>\n",
       "      <td>0.810</td>\n",
       "      <td>0.002707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sigmoid</td>\n",
       "      <td>YCrCb</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>9.09</td>\n",
       "      <td>6108.0</td>\n",
       "      <td>0.55</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>linear</td>\n",
       "      <td>RGB</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>9.09</td>\n",
       "      <td>6108.0</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.985</td>\n",
       "      <td>0.000652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>linear</td>\n",
       "      <td>YCrCb</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>9.25</td>\n",
       "      <td>7872.0</td>\n",
       "      <td>0.69</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>linear</td>\n",
       "      <td>YCrCb</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>32</td>\n",
       "      <td>16</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>9.14</td>\n",
       "      <td>8412.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>linear</td>\n",
       "      <td>YCrCb</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>16</td>\n",
       "      <td>32</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>9.09</td>\n",
       "      <td>6156.0</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.995</td>\n",
       "      <td>0.000551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>linear</td>\n",
       "      <td>YCrCb</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>9.09</td>\n",
       "      <td>5340.0</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.990</td>\n",
       "      <td>0.000451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>linear</td>\n",
       "      <td>YCrCb</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.35</td>\n",
       "      <td>768.0</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.995</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     kernel color_space  orient  pix_per_cell  cell_per_block  hog_channel  \\\n",
       "0    linear       YCrCb       9             8               2           -1   \n",
       "1    linear       YCrCb      12             8               2            0   \n",
       "2       rbf       YCrCb       9             8               2           -1   \n",
       "3      poly       YCrCb       9             8               2           -1   \n",
       "4   sigmoid       YCrCb       9             8               2           -1   \n",
       "5    linear         RGB       9             8               2           -1   \n",
       "6    linear       YCrCb      12             8               2           -1   \n",
       "7    linear       YCrCb       9             8               2           -1   \n",
       "8    linear       YCrCb       9             8               2           -1   \n",
       "9    linear       YCrCb       9             8               2           -1   \n",
       "10   linear       YCrCb       9             8               2           -1   \n",
       "\n",
       "    spatial_size  hist_bins  spatial_feat  hist_feat  hog_feat  \\\n",
       "0             16         16          True       True      True   \n",
       "1              8         16          True       True      True   \n",
       "2             16         16          True       True      True   \n",
       "3             16         16          True       True      True   \n",
       "4             16         16          True       True      True   \n",
       "5             16         16          True       True      True   \n",
       "6             16         16          True       True      True   \n",
       "7             32         16          True       True      True   \n",
       "8             16         32          True       True      True   \n",
       "9             16         16         False       True      True   \n",
       "10            16         16          True      False     False   \n",
       "\n",
       "    time_to_extract_features  features_vector_length  training_time  accuracy  \\\n",
       "0                       9.10                  6108.0           0.47     0.995   \n",
       "1                       3.71                  2592.0           0.18     0.990   \n",
       "2                       9.07                  6108.0           1.09     0.995   \n",
       "3                       9.09                  6108.0           2.25     0.810   \n",
       "4                       9.09                  6108.0           0.55     1.000   \n",
       "5                       9.09                  6108.0           0.57     0.985   \n",
       "6                       9.25                  7872.0           0.69     1.000   \n",
       "7                       9.14                  8412.0           0.63     1.000   \n",
       "8                       9.09                  6156.0           0.47     0.995   \n",
       "9                       9.09                  5340.0           0.41     0.990   \n",
       "10                      0.35                   768.0           0.06     0.995   \n",
       "\n",
       "    prediction_time  \n",
       "0          0.000551  \n",
       "1          0.000200  \n",
       "2          0.001353  \n",
       "3          0.002707  \n",
       "4          0.000702  \n",
       "5          0.000652  \n",
       "6          0.000852  \n",
       "7          0.000752  \n",
       "8          0.000551  \n",
       "9          0.000451  \n",
       "10         0.000000  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Automated test of different extraction parameters and SVC kernels and parameters\n",
    "\n",
    "# load svc that contains all needed parameters in each line\n",
    "para_pd = pd.read_csv(\"extraction_parameters.csv\")\n",
    "para_pd['spatial_feat'] = para_pd['spatial_feat'].astype('bool')\n",
    "para_pd['hist_feat'] = para_pd['hist_feat'].astype('bool')\n",
    "para_pd['hog_feat'] = para_pd['hog_feat'].astype('bool')\n",
    "\n",
    "\n",
    "# debug output\n",
    "print(para_pd.shape)\n",
    "\n",
    "for index, para_row in para_pd.iterrows():\n",
    "    \n",
    "    # TODO: check if line is already calculated. If yes: \"continue\"\n",
    "    #if para_row['accuracy'] \n",
    "    \n",
    "    print('Index: ', index)\n",
    "    kernel = para_row['kernel']\n",
    "    color_space = para_row['color_space']\n",
    "    orient = para_row['orient']\n",
    "    pix_per_cell = para_row['pix_per_cell']\n",
    "    cell_per_block = para_row['cell_per_block']\n",
    "    hog_channel = para_row['hog_channel']\n",
    "    spatial_size = (para_row['spatial_size'], para_row['spatial_size'])\n",
    "    hist_bins = para_row['hist_bins']\n",
    "    spatial_feat = para_row['spatial_feat']\n",
    "    hist_feat = para_row['hist_feat']\n",
    "    hog_feat = para_row['hog_feat']\n",
    "        \n",
    "    \n",
    "    t = time.time()\n",
    "    car_features = extract_features(cars, color_space=color_space,\n",
    "                                    spatial_size=spatial_size, hist_bins=hist_bins,\n",
    "                                    orient=orient, pix_per_cell=pix_per_cell,\n",
    "                                    cell_per_block=cell_per_block,\n",
    "                                    hog_channel=hog_channel, spatial_feat=spatial_feat,\n",
    "                                    hist_feat=hist_feat, hog_feat=hog_feat)\n",
    "    \n",
    "    notcar_features = extract_features(notcars, color_space=color_space,\n",
    "                                       spatial_size=spatial_size, hist_bins=hist_bins,\n",
    "                                       orient=orient, pix_per_cell=pix_per_cell,\n",
    "                                       cell_per_block=cell_per_block,\n",
    "                                       hog_channel=hog_channel, spatial_feat=spatial_feat,\n",
    "                                       hist_feat=hist_feat, hog_feat=hog_feat)\n",
    "\n",
    "    t2 = time.time()\n",
    "    para_pd.loc[index, 'time_to_extract_features'] = round(t2 - t, 2)\n",
    "    \n",
    "    X = np.vstack((car_features, notcar_features)).astype(np.float64)\n",
    "    # Fit a per-column scaler\n",
    "    X_scaler = StandardScaler().fit(X)\n",
    "    # Apply the scaler to X\n",
    "    scaled_X = X_scaler.transform(X)\n",
    "\n",
    "    # Define the labels vector\n",
    "    y = np.hstack((np.ones(len(car_features)), np.zeros(len(notcar_features))))\n",
    "\n",
    "    # Split up data into randomized training and test sets\n",
    "    rand_state = np.random.randint(0, 100)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        scaled_X, y, test_size=0.2, random_state=rand_state)\n",
    "\n",
    "    para_pd.loc[index, 'features_vector_length'] = len(X_train[0])\n",
    "    # Use a linear SVC\n",
    "    svc = SVC(kernel=kernel)\n",
    "    # Check the training time for the SVC\n",
    "    t = time.time()\n",
    "    svc.fit(X_train, y_train)\n",
    "    t2 = time.time()\n",
    "    para_pd.loc[index, 'training_time'] = round(t2 - t, 2)\n",
    "    # Check the score of the SVC\n",
    "    para_pd.loc[index, 'accuracy'] = round(svc.score(X_test, y_test), 4)    \n",
    "    \n",
    "    # extract 10 random samples from dataset and run prediction\n",
    "    \n",
    "    t = time.time()\n",
    "    prediction = svc.predict(X_test[0:10])\n",
    "    t2 = time.time()\n",
    "    para_pd.loc[index, 'prediction_time'] = round((t2 - t)/10, 9)\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    for window in windows:\n",
    "        #3) Extract the test window from original image\n",
    "        test_img = cv2.resize(img[window[0][1]:window[1][1], window[0][0]:window[1][0]], (64, 64))      \n",
    "        #4) Extract features for that window using single_img_features()\n",
    "        features = single_img_features(test_img, color_space=color_space, \n",
    "                            spatial_size=spatial_size, hist_bins=hist_bins, \n",
    "                            orient=orient, pix_per_cell=pix_per_cell, \n",
    "                            cell_per_block=cell_per_block, \n",
    "                            hog_channel=hog_channel, spatial_feat=spatial_feat, \n",
    "                            hist_feat=hist_feat, hog_feat=hog_feat)\n",
    "        #5) Scale extracted features to be fed to classifier\n",
    "        test_features = scaler.transform(np.array(features).reshape(1, -1))\n",
    "        #6) Predict using your classifier\n",
    "        prediction = clf.predict(test_features)\n",
    "        #7) If positive (prediction == 1) then save the window\n",
    "    \"\"\"\n",
    "    #print(para_row)\n",
    "\n",
    "\n",
    "\n",
    "# save pandas file back to hard drive\n",
    "para_pd.to_csv(\"extraction_parameters_result.csv\", sep=';', index=False)\n",
    "para_pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_image(image):\n",
    "    # NOTE: The output you return should be a color image (3 channel) for processing video below\n",
    "    # TODO: put your pipeline here,\n",
    "    # you should return the final output (image where lines are drawn on lanes)\n",
    "\n",
    "    return pipeline_vehicle_detection(image, debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "project_output = 'project_video_output.mp4'\n",
    "## To speed up the testing process you may want to try your pipeline on a shorter subclip of the video\n",
    "## To do so add .subclip(start_second,end_second) to the end of the line below\n",
    "## Where start_second and end_second are integer values representing the start and end of the subclip\n",
    "## You may also uncomment the following line for a subclip of the first 5 seconds\n",
    "##clip1 = VideoFileClip(\"test_videos/solidWhiteRight.mp4\").subclip(0,5)\n",
    "left = Line('left')\n",
    "right = Line('right')\n",
    "clip1 = VideoFileClip(\"project_video.mp4\")\n",
    "project_clip = clip1.fl_image(process_image) #NOTE: this function expects color images!!\n",
    "%time project_clip.write_videofile(project_output, audio=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "project_output = 'challenge_video_output.mp4'\n",
    "## To speed up the testing process you may want to try your pipeline on a shorter subclip of the video\n",
    "## To do so add .subclip(start_second,end_second) to the end of the line below\n",
    "## Where start_second and end_second are integer values representing the start and end of the subclip\n",
    "## You may also uncomment the following line for a subclip of the first 5 seconds\n",
    "##clip1 = VideoFileClip(\"test_videos/solidWhiteRight.mp4\").subclip(0,5)\n",
    "left = Line('left')\n",
    "right = Line('right')\n",
    "clip1 = VideoFileClip(\"challenge_video.mp4\")\n",
    "project_clip = clip1.fl_image(process_image) #NOTE: this function expects color images!!\n",
    "%time project_clip.write_videofile(project_output, audio=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Harder Challenge Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "project_output = 'harder_challenge_video_output.mp4'\n",
    "## To speed up the testing process you may want to try your pipeline on a shorter subclip of the video\n",
    "## To do so add .subclip(start_second,end_second) to the end of the line below\n",
    "## Where start_second and end_second are integer values representing the start and end of the subclip\n",
    "## You may also uncomment the following line for a subclip of the first 5 seconds\n",
    "##clip1 = VideoFileClip(\"test_videos/solidWhiteRight.mp4\").subclip(0,5)\n",
    "left = Line('left')\n",
    "right = Line('right')\n",
    "clip1 = VideoFileClip(\"harder_challenge_video.mp4\")\n",
    "project_clip = clip1.fl_image(process_image) #NOTE: this function expects color images!!\n",
    "%time project_clip.write_videofile(project_output, audio=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backup\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sobel_parameters(img, \n",
    "                     thresh_abs_x = (0.01, 1), \n",
    "                     thresh_abs_y = (0.01, 1), \n",
    "                     thresh_mag = (0.05, 1), \n",
    "                     thresh_dir = (0, 1)):\n",
    "    \n",
    "    # vertical contrast borders. Note that a Scharr kernel is used here for better performance \n",
    "    sobelx = cv2.Sobel(img, cv2.CV_64F, 1, 0, ksize=-1)\n",
    "    \n",
    "    # horizontal contrast borders. Scharr kernel\n",
    "    sobely = cv2.Sobel(img, cv2.CV_64F, 0, 1, ksize=-1)\n",
    "    \n",
    "    # diagonal contrast borders high->low. Scharr kernel\n",
    "    kernel10 = np.array([[0, -3, -10],[3, 0, -3],[10, 3, 0]]) \n",
    "    sobel10 = cv2.filter2D(img, -1, kernel10)\n",
    "    \n",
    "    # diagonal contrast borders low->high. Scharr kernel\n",
    "    kernel01 = np.array([[10, 3, 0],[3, 0, -3],[0, -3, -10]]) \n",
    "    sobel01 = cv2.filter2D(img, -1, kernel01)\n",
    "     \n",
    "    # calculate value (sharpness) of contrast border and apply threshold to it\n",
    "    abs_sobelx = np.absolute(sobelx)\n",
    "    abs_sobely = np.absolute(sobely)\n",
    "    \n",
    "    # threshold values \n",
    "    scaled_sobelx = abs_sobelx/np.max(abs_sobelx)\n",
    "    binary_output_x = np.zeros_like(scaled_sobelx)\n",
    "    binary_output_x[(scaled_sobelx >= thresh_abs_x[0]) & (scaled_sobelx <= thresh_abs_x[1])] = 1\n",
    "    \n",
    "    scaled_sobely = abs_sobely/np.max(abs_sobely)\n",
    "    binary_output_y = np.zeros_like(scaled_sobely)\n",
    "    binary_output_y[(scaled_sobely >= thresh_abs_y[0]) & (scaled_sobely <= thresh_abs_y[1])] = 1\n",
    "    \n",
    "    mag = np.sqrt(sobelx**2 + sobely**2)\n",
    "    scaled_mag = mag/np.max(mag)\n",
    "    binary_output_mag = np.zeros_like(scaled_mag)\n",
    "    binary_output_mag[(scaled_mag >= thresh_mag[0]) & (scaled_mag <= thresh_mag[1])] = 1\n",
    "    \n",
    "    dir_grad = np.arctan2(abs_sobely, abs_sobelx)\n",
    "    binary_output_dir = np.zeros_like(dir_grad)\n",
    "    binary_output_dir[(dir_grad > thresh_dir[0]) & (dir_grad <= thresh_dir[1])] = 1\n",
    "    \n",
    "    # put all binary images into one big numpy array\n",
    "    bin_out = img.copy()\n",
    "    bin_out = np.dstack((bin_out, binary_output_x))\n",
    "    bin_out = np.dstack((bin_out, binary_output_y))\n",
    "    bin_out = np.dstack((bin_out, binary_output_mag))\n",
    "    bin_out = np.dstack((bin_out, binary_output_dir))\n",
    "    \n",
    "    dir_mag = np.zeros_like(binary_output_dir)\n",
    "    dir_mag[(bin_out[:,:,3] == 1) & (bin_out[:,:,4] == 1)] = 1\n",
    "    bin_out = np.dstack((bin_out, dir_mag))\n",
    "    \n",
    "    combined = np.zeros_like(binary_output_dir)\n",
    "    combined[(bin_out[:,:,1] == 1) & (bin_out[:,:,2] == 1) & (bin_out[:,:,3] == 1) & (bin_out[:,:,4] == 1)] = 1\n",
    "    bin_out = np.dstack((bin_out, combined))\n",
    "    \n",
    "    \n",
    "    return bin_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "img = mpimg.imread('./test_images/test5.jpg')\n",
    "plt.figure(figsize=(17,5))\n",
    "plt.imshow(img)\n",
    "\n",
    "bin_out = sobel_parameters(img)\n",
    "plt.figure(figsize=(17,10))\n",
    "plt.imshow(bin_out[:,:,1:4], cmap='gray')\n",
    "\n",
    "\n",
    "plt.figure(figsize=(17,10))\n",
    "plt.imshow(bin_out[:,:,1], cmap='gray')\n",
    "plt.figure(figsize=(17,10))\n",
    "plt.imshow(bin_out[:,:,2], cmap='gray')\n",
    "plt.figure(figsize=(17,10))\n",
    "plt.imshow(bin_out[:,:,3], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.html.widgets import *\n",
    "\n",
    "\n",
    "def sobel(thresh_abs_x_low = 0.1, thresh_abs_x_high = 1,\n",
    "         thresh_abs_y_low = 0, thresh_abs_y_high = 1, \n",
    "         thresh_mag_low = 0, thresh_mag_high = 1,\n",
    "         thresh_dir_low = 0, thresh_dir_high=0.67):\n",
    "    \n",
    "    \n",
    "    img = mpimg.imread('./test_images/test1.jpg')\n",
    "    gray = get_redchannel(img)\n",
    "    birdview = birdview_warp(gray)\n",
    "    bin_out = sobel_parameters(birdview, \n",
    "                               thresh_abs_x = (thresh_abs_x_low, thresh_abs_x_high), \n",
    "                                thresh_abs_y = (thresh_abs_y_low, thresh_abs_y_high), \n",
    "                                thresh_mag = (thresh_mag_low, thresh_mag_high), \n",
    "                                thresh_dir = (thresh_dir_low, thresh_dir_high))\n",
    "    \n",
    "    plt.figure(figsize=(17,10))\n",
    "    #out = np.dstack((bin_out[:,:,1], bin_out[:,:,2], bin_out[:,:,5]))\n",
    "    plt.imshow(bin_out[:,:,6], cmap='gray')\n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "interact(sobel, thresh_abs_x_low = (0,1,0.01), thresh_abs_x_high = (0,1,0.01),\n",
    "         thresh_abs_y_low = (0,1,0.01), thresh_abs_y_high = (0,1,0.01), \n",
    "         thresh_mag_low = (0,1,0.01), thresh_mag_high = (0,1,0.01),\n",
    "         thresh_dir_low = (0,1.57,0.01), thresh_dir_high= (0,1.57,0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "img = mpimg.imread('./test_images/test1.jpg')\n",
    "print_example_images(img, birdview_warp(img))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## sobel demo\n",
    "img = mpimg.imread('./test_images/circle.png')\n",
    "plt.figure(figsize=(17,5))\n",
    "plt.imshow(img)\n",
    "\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=-1)\n",
    "sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=-1)\n",
    "print(sobelx.shape, sobelx.max(), sobelx.min())\n",
    "placeholder = gray.copy()\n",
    "\n",
    "# set parameters\n",
    "thresh_abs_x = (150, 255)\n",
    "thresh_abs_y = (150, 255)\n",
    "thresh_mag = (150, 255)\n",
    "thresh_dir = (0, 0.1)\n",
    "\n",
    "# abs\n",
    "abs_sobelx = np.absolute(sobelx)\n",
    "scaled_sobelx = np.uint8(255*abs_sobelx/np.max(abs_sobelx))\n",
    "binary_output_x = np.zeros_like(scaled_sobelx)\n",
    "binary_output_x[(scaled_sobelx > thresh_abs_x[0]) & (scaled_sobelx < thresh_abs_x[1])] = 1\n",
    "placeholder = np.dstack((placeholder, binary_output_x))\n",
    "\n",
    "abs_sobely = np.absolute(sobely)\n",
    "scaled_sobely = np.uint8(255*abs_sobely/np.max(abs_sobely))\n",
    "binary_output_y = np.zeros_like(scaled_sobely)\n",
    "binary_output_y[(scaled_sobely > thresh_abs_y[0]) & (scaled_sobely < thresh_abs_y[1])] = 1\n",
    "placeholder = np.dstack((placeholder, binary_output_y))\n",
    "\n",
    "# mag\n",
    "mag = np.sqrt(sobelx**2 + sobely**2)\n",
    "scaled_mag = np.uint8(255*mag/np.max(mag))\n",
    "binary_output_mag = np.zeros_like(scaled_mag)\n",
    "binary_output_mag[(scaled_mag > thresh_mag[0]) & (scaled_mag < thresh_mag[1])] = 1\n",
    "placeholder = np.dstack((placeholder, binary_output_mag))\n",
    "\n",
    "# direction\n",
    "#thresh_dir = (thresh_dir*np.pi)-(np.pi/2)\n",
    "dir_grad = np.arctan2(abs_sobely, abs_sobelx)\n",
    "binary_output_dir = np.zeros_like(dir_grad)\n",
    "binary_output_dir[(dir_grad > thresh_dir[0]) & (dir_grad <= thresh_dir[1])] = 1\n",
    "placeholder = np.dstack((placeholder, binary_output_dir))\n",
    "\n",
    "\n",
    "plt.figure(figsize=(17,5))\n",
    "plt.imshow(gray, cmap='gray')\n",
    "\n",
    "plt.figure(figsize=(17,5))\n",
    "plt.imshow(binary_output_x, cmap='gray')\n",
    "\n",
    "\n",
    "plt.figure(figsize=(17,5))\n",
    "plt.imshow(binary_output_y, cmap='gray')\n",
    "\n",
    "plt.figure(figsize=(17,5))\n",
    "plt.imshow(binary_output_mag, cmap='gray')\n",
    "\n",
    "plt.figure(figsize=(17,5))\n",
    "plt.imshow(binary_output_dir, cmap='gray')\n",
    "\n",
    "print(placeholder.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "abs_sobelx = np.absolute(sobelx)\n",
    "print(abs_sobelx.min(), abs_sobelx.max())\n",
    "scaled_sobelx = abs_sobelx/np.max(abs_sobelx)\n",
    "print(scaled_sobelx.min(), scaled_sobelx.max())\n",
    "binary_output_x = np.zeros_like(scaled_sobelx)\n",
    "binary_output_x[(scaled_sobelx >= thresh_abs_x[0]) & (scaled_sobelx <= thresh_abs_x[1])] = 1\n",
    "placeholder = np.dstack((placeholder, binary_output_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# color space demo\n",
    "from skimage import exposure\n",
    "\n",
    "img = mpimg.imread('./test_images/vlcsnap-2017-08-02-08h34m19s558.jpg')\n",
    "plt.figure(figsize=(17,5))\n",
    "plt.imshow(img)\n",
    "img = hist_equ(img)\n",
    "\n",
    "plt.figure(figsize=(17,5))\n",
    "plt.imshow(img)\n",
    "\n",
    "img_hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "#img_hsv= img\n",
    "\n",
    "plt.figure(figsize=(17,5))\n",
    "plt.imshow(img_hsv[:,:,0], cmap='gray')\n",
    "plt.figure(figsize=(17,5))\n",
    "plt.imshow(img_hsv[:,:,1], cmap='gray')\n",
    "plt.figure(figsize=(17,5))\n",
    "plt.imshow(img_hsv[:,:,2], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# lane curvature\n",
    "y_eval = 720\n",
    "\n",
    "\n",
    "\n",
    "left_curverad = ((1 + (2*left_fit_cr[0]*y_eval*ym_per_pix + left_fit_cr[1])**2)**1.5) / np.abs(2*left_fit_cr[0])\n",
    "right_curverad = ((1 + (2*right_fit_cr[0]*y_eval*ym_per_pix + right_fit_cr[1])**2)**1.5) / np.abs(2*right_fit_cr[0])\n",
    "print(left_curverad, right_curverad, 'in meters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# test with custom sobel kernel\n",
    "img = mpimg.imread('./test_images/circle.png')\n",
    "\n",
    "kernel10 = np.array([[0, -3, -10],[3, 0, -3],[10, 3, 0]]) \n",
    "\n",
    "kernel01 = np.array([[10, 3, 0],[3, 0, -3],[0, -3, -10]]) \n",
    "\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "sobel_custom1 = cv2.filter2D(gray, -1, kernel10)\n",
    "plt.figure(figsize=(17,10))\n",
    "plt.imshow(sobel_custom1, cmap='gray')\n",
    "\n",
    "sobel_custom2 = cv2.filter2D(gray, -1, kernel01)\n",
    "plt.figure(figsize=(17,10))\n",
    "plt.imshow(sobel_custom2, cmap='gray')\n",
    "\n",
    "sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=-1)\n",
    "plt.figure(figsize=(17,10))\n",
    "plt.imshow(sobelx, cmap='gray')\n",
    "\n",
    "sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=-1)\n",
    "plt.figure(figsize=(17,10))\n",
    "plt.imshow(sobely, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = np.array(range(0,3))\n",
    "\n",
    "for n in range(6,15):\n",
    "    print(x.size)\n",
    "    x = np.append(x, n)\n",
    "    if x.size > 5:\n",
    "        x = x[1:]\n",
    "    print(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = [0,1,2]\n",
    "\n",
    "for n in range(6,15):\n",
    "    print(len(x))\n",
    "    x.append(n)\n",
    "    if len(x) > 5:\n",
    "        x = x[1:]\n",
    "    print(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = np.array([[50, 48, 4, 3, 2, 1, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(np.median(a), np.mean(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = np.array([])\n",
    "a.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "left_fit.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class _alt_Lines():\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.last_detected_lines = 0\n",
    "        \n",
    "        self.left_fit_pool = np.array([])\n",
    "        self.curvature_left = 0\n",
    "           \n",
    "        self.right_fit_pool = []\n",
    "        self.curvature_left = 0\n",
    "        \n",
    "        self.offset_lane = 0\n",
    "        \n",
    "    def process_img(self, img):\n",
    "        if self.last_detected_lines == 0:\n",
    "            left_fit, right_fit, left_fit_cr, right_fit_cr = find_lines(img)\n",
    "            print(left_fit, right_fit, left_fit_cr, right_fit_cr)\n",
    "        else:\n",
    "            #TODO - simple line finding here\n",
    "            print('bla')\n",
    "        \n",
    "        if self.sanitycheck_parameters(left_fit, right_fit, left_fit_cr, right_fit_cr):     \n",
    "            self.update_parameters(left_fit, right_fit, left_fit_cr, right_fit_cr)\n",
    "        \n",
    "        \n",
    "    def sanitycheck_parameters(self, left_fit, right_fit, left_fit_cr, right_fit_cr): \n",
    "        #TODO\n",
    "        if 1 == 1:\n",
    "            self.last_detected_lines += 1\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def update_parameters(self, left_fit, right_fit, left_fit_cr, right_fit_cr):\n",
    "        \n",
    "        \n",
    "        if self.left_fit_pool.size == 0:\n",
    "            self.left_fit_pool = left_fit\n",
    "        else:\n",
    "            self.left_fit_pool = np.vstack((self.left_fit_pool, left_fit))\n",
    "            if self.left_fit_pool.shape[1] > 10:\n",
    "                self.left_fit_pool = self.left_fit_pool[1:,:]\n",
    "        print(np.median(left_fit_pool[:,0]))\n",
    "        print(np.median(left_fit_pool[:,1]))\n",
    "        print(np.median(left_fit_pool[:,2]))\n",
    "         \n",
    "        \n",
    "        # Lane curvature  ##TODO: this has to be smoothed out as well. (np.median(self.left_fit_pool))\n",
    "        y_eval = img.shape[0]\n",
    "        self.curvature_left = ((1 + (2*left_fit_cr[0]*y_eval*ym_per_pix + left_fit_cr[1])**2)**1.5) / np.abs(2*left_fit_cr[0])\n",
    "        self.curvature_right = ((1 + (2*right_fit_cr[0]*y_eval*ym_per_pix + right_fit_cr[1])**2)**1.5) / np.abs(2*right_fit_cr[0])\n",
    "        print(self.curvature_left, self.curvature_right, 'in meters')\n",
    "        \n",
    "        ## Offset\n",
    "        y= img.shape[0]\n",
    "        xl = left_fit[0]* y**2 + left_fit[1]*y + left_fit[2]  \n",
    "        xr = right_fit[0]* y**2 + right_fit[1]*y + right_fit[2]\n",
    "        print('left: ', xl)\n",
    "        print('right: ', xr)\n",
    "        center_point = img.shape[1]/2\n",
    "        self.offset_lane = (center_point - ((xr + xl)/2))*xm_per_pix\n",
    "        print('Offset from middle of the lane: ', self.offset_lane*100, 'cm')\n",
    "\n",
    "        \n",
    "## TEST         \n",
    "lines = Lines()\n",
    "img = mpimg.imread('./test_images/test5.jpg')\n",
    "red = get_redchannel(img)\n",
    "thresh = apply_threshold_dynamic2(red, percentile=0.03)\n",
    "birdview = birdview_warp(thresh)\n",
    "lines.process_img(birdview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_lines(img):\n",
    "\n",
    "    assert img.ndim == 2\n",
    "    \n",
    "    histogram = np.sum(img[360:,350:930], axis=0)\n",
    "    midpoint = np.int(histogram.shape[0]/2)\n",
    "    left_peak = np.argmax(histogram[:midpoint]) + 350\n",
    "    right_peak = np.argmax(histogram[midpoint:]) + midpoint + 350\n",
    "    print('left_peak: ', left_peak)\n",
    "    print('right_peak: ', right_peak)\n",
    "    \n",
    "    nwindows = 9\n",
    "    window_height = np.int(img.shape[0]/nwindows)\n",
    "    #left_peak = 500\n",
    "    #right_peak = 800\n",
    "    margin = 100\n",
    "    adjust_window_pos = 50\n",
    "    left_lane_coordx = np.array([])\n",
    "    left_lane_coordy = np.array([])\n",
    "    right_lane_coordx = np.array([])\n",
    "    right_lane_coordy = np.array([])\n",
    "\n",
    "    for n in range(nwindows):\n",
    "        window_lower_border = img.shape[0] - n*window_height\n",
    "        window_slice = img[window_lower_border-window_height:window_lower_border, :]\n",
    "\n",
    "        slice_left_window = window_slice[: , left_peak-margin:left_peak+margin]\n",
    "        slice_left_line_coordy, slice_left_line_coordx = np.nonzero(slice_left_window)\n",
    "        slice_left_line_coordy += window_lower_border - window_height\n",
    "        slice_left_line_coordx += left_peak - 100\n",
    "\n",
    "        left_lane_coordx = np.append(left_lane_coordx, slice_left_line_coordx)\n",
    "        left_lane_coordy = np.append(left_lane_coordy, slice_left_line_coordy)\n",
    "\n",
    "        if slice_left_line_coordx.size > adjust_window_pos:\n",
    "            left_peak = np.int(np.mean(slice_left_line_coordx))\n",
    "\n",
    "\n",
    "        slice_right_window = window_slice[: , right_peak-margin:right_peak+margin]\n",
    "        slice_right_line_coordy, slice_right_line_coordx = np.nonzero(slice_right_window)\n",
    "        slice_right_line_coordy += window_lower_border - window_height\n",
    "        slice_right_line_coordx += right_peak - 100\n",
    "\n",
    "        right_lane_coordx = np.append(right_lane_coordx, slice_right_line_coordx)\n",
    "        right_lane_coordy = np.append(right_lane_coordy, slice_right_line_coordy)\n",
    "\n",
    "        if slice_right_line_coordx.size > adjust_window_pos:\n",
    "            right_peak = np.int(np.mean(slice_right_line_coordx))\n",
    "\n",
    "\n",
    "    assert left_lane_coordx.size == left_lane_coordy.size\n",
    "    assert right_lane_coordx.size == right_lane_coordy.size\n",
    "\n",
    "    left_fit_cr = np.polyfit(left_lane_coordy*ym_per_pix, left_lane_coordx*xm_per_pix, 2)\n",
    "    right_fit_cr = np.polyfit(right_lane_coordy*ym_per_pix, right_lane_coordx*xm_per_pix, 2)    \n",
    "    \n",
    "    left_fit = np.polyfit(left_lane_coordy, left_lane_coordx, 2)\n",
    "    right_fit = np.polyfit(right_lane_coordy, right_lane_coordx, 2)    \n",
    "    \n",
    "\n",
    "    return left_fit, right_fit, left_fit_cr, right_fit_cr\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "img = mpimg.imread('./test_images/test5.jpg')\n",
    "red = get_redchannel(img)\n",
    "thresh = apply_threshold_dynamic2(red, percentile=0.03)\n",
    "birdview = birdview_warp(thresh)\n",
    "left_fit, right_fit, left_fit_cr, right_fit_cr = find_lines(birdview)\n",
    "print(left_fit, right_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def findlines(img):\n",
    "    \n",
    "    histogram = np.sum(img[int(img.shape[0]/2):,400:880], axis=0)\n",
    "    # Create an output image to draw on and  visualize the result\n",
    "    out_img = np.dstack((img, img, img))*255\n",
    "    # Find the peak of the left and right halves of the histogram\n",
    "    # These will be the starting point for the left and right lines\n",
    "    midpoint = np.int(histogram.shape[0]/2)\n",
    "    leftx_base = np.argmax(histogram[:midpoint])\n",
    "    rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "\n",
    "    # Choose the number of sliding windows\n",
    "    nwindows = 9\n",
    "    # Set height of windows\n",
    "    window_height = np.int(img.shape[0]/nwindows)\n",
    "    # Identify the x and y positions of all nonzero pixels in the image\n",
    "    nonzero = img.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    # Current positions to be updated for each window\n",
    "    leftx_current = leftx_base + 400\n",
    "    rightx_current = rightx_base + 400\n",
    "    # Set the width of the windows +/- margin\n",
    "    margin = 100\n",
    "    # Set minimum number of pixels found to recenter window\n",
    "    minpix = 50\n",
    "    # Create empty lists to receive left and right lane pixel indices\n",
    "    left_lane_inds = []\n",
    "    right_lane_inds = []\n",
    "\n",
    "    # Step through the windows one by one\n",
    "    for window in range(nwindows):\n",
    "        # Identify window boundaries in x and y (and right and left)\n",
    "        win_y_low = img.shape[0] - (window+1)*window_height\n",
    "        win_y_high = img.shape[0] - window*window_height\n",
    "        win_xleft_low = leftx_current - margin\n",
    "        win_xleft_high = leftx_current + margin\n",
    "        win_xright_low = rightx_current - margin\n",
    "        win_xright_high = rightx_current + margin\n",
    "        # Draw the windows on the visualization image\n",
    "        cv2.rectangle(out_img,(win_xleft_low,win_y_low),(win_xleft_high,win_y_high),(0,255,0), 2) \n",
    "        cv2.rectangle(out_img,(win_xright_low,win_y_low),(win_xright_high,win_y_high),(0,255,0), 2) \n",
    "        # Identify the nonzero pixels in x and y within the window\n",
    "        good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & (nonzerox >= win_xleft_low) & (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "        good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & (nonzerox >= win_xright_low) & (nonzerox < win_xright_high)).nonzero()[0]\n",
    "        # Append these indices to the lists\n",
    "        left_lane_inds.append(good_left_inds)\n",
    "        right_lane_inds.append(good_right_inds)\n",
    "        # If you found > minpix pixels, recenter next window on their mean position\n",
    "        if len(good_left_inds) > minpix:\n",
    "            leftx_current = np.int(np.mean(nonzerox[good_left_inds]))\n",
    "        if len(good_right_inds) > minpix:        \n",
    "            rightx_current = np.int(np.mean(nonzerox[good_right_inds]))\n",
    "\n",
    "    # Concatenate the arrays of indices\n",
    "    left_lane_inds = np.concatenate(left_lane_inds)\n",
    "    right_lane_inds = np.concatenate(right_lane_inds)\n",
    "\n",
    "    # Extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds] \n",
    "\n",
    "    \n",
    "    \n",
    "    # Fit a second order polynomial to each\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "    \n",
    "    # Generate x and y values for plotting\n",
    "    ploty = np.linspace(0, img.shape[0]-1, img.shape[0] )\n",
    "    left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "    right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "\n",
    "    out_img[nonzeroy[left_lane_inds], nonzerox[left_lane_inds]] = [255, 0, 0]\n",
    "    out_img[nonzeroy[right_lane_inds], nonzerox[right_lane_inds]] = [0, 0, 255]\n",
    "    \n",
    "    print(nonzeroy[left_lane_inds])\n",
    "    \n",
    "    \n",
    "    plt.figure(figsize=(17,5))\n",
    "    plt.imshow(out_img)\n",
    "    plt.plot(left_fitx, ploty, color='yellow')\n",
    "    plt.plot(right_fitx, ploty, color='yellow')\n",
    "    plt.xlim(0, 1280)\n",
    "    plt.ylim(720, 0)\n",
    "    plt.show()\n",
    "    \n",
    "    return left_fit, right_fit, leftx, lefty, rightx, righty\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "## Demo\n",
    "img = mpimg.imread('./test_images/test4.jpg')\n",
    "red = get_redchannel(img)\n",
    "thresh = apply_threshold_dynamic2(red, percentile=0.03)\n",
    "birdview = birdview_warp(thresh)\n",
    "left_fit, right_fit, leftx, lefty, rightx, righty = findlines(birdview)\n",
    "print_example_images(img, thresh)\n",
    "\n",
    "print(leftx)\n",
    "print(lefty)\n",
    "\n",
    "# Generate x and y values for plotting\n",
    "ploty = np.linspace(0, img.shape[0]-1, img.shape[0] )\n",
    "left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "\n",
    "\n",
    "plt.figure(figsize=(17,5))\n",
    "plt.imshow(birdview_warp(img), cmap='gray')\n",
    "plt.plot(left_fitx, ploty, color='yellow')\n",
    "plt.plot(right_fitx, ploty, color='yellow')\n",
    "plt.xlim(0, 1280)\n",
    "plt.ylim(720, 0)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "left_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = np.vstack((left_fit, left_fit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = np.vstack((test, right_fit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test[1:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = np.array([1,1,1])\n",
    "for n in range(10):\n",
    "    test = np.vstack((test, np.array([n,n,n])))\n",
    "    \n",
    "    if test.shape[0] > 3:\n",
    "        test = test[1:,:]\n",
    "    print(test)\n",
    "    #print(test.mean())\n",
    "    print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
